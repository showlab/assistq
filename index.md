## Welcome to AssistQ

You can find our paper [AssistQ](https://arxiv.org/abs/2203.04203) 


### Abstract

Abstract. A long-standing goal of intelligent assistants such as AR
glasses/robots has been to assist users in affordance-centric real-world
scenarios, such as “how can I run the microwave for 1 minute?”. However, there is still no clear task definition and suitable benchmarks. In this
paper, we define a new task called Affordance-centric Question-driven
Task Completion, where the AI assistant should learn from instructional
videos and scripts to guide the user step-by-step. To support the task,
we constructed AssistQ, a new dataset comprising 529 question-answer
samples derived from 100 newly filmed first-person videos. Each question should be completed with multi-step guidances by inferring from
visual details (e.g., buttons’ position) and textural details (e.g., actions
like press/turn). To address this unique task, we developed a Questionto-Actions (Q2A) model that significantly outperforms several baseline
methods while still having large room for improvement. We expect our
task and dataset to advance Egocentric AI Assistant’s development. 

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [Basic writing and formatting syntax](https://docs.github.com/en/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/Chenanism777/UROP_CV_HELMETDETECTION/settings/pages). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://docs.github.com/categories/github-pages-basics/) or [contact support](https://support.github.com/contact) and we’ll help you sort it out.
